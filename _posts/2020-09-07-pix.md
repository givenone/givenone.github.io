---
layout: post
title: 직관적 논리적 설명
tags: [사설]
author: givenone
excerpt_separator: <!--more-->
---

관련 자료를 찾다가 딥러닝 (GAN과 VAE 등)을 굉장히 잘 설명한 글이 있어서 긁어왔다. 딥러닝 모델에 대해 직관적인 Insight가 잘 담긴 설명이다.

나도 저렇게 설명을 잘하고 싶다. 이것이 박사와 척척학사의 차이인 것인가. 지식의 깊이가 다르다.

그냥 아는 것과 잘 설명하는 건 다르다. 그냥 아는 것이 10% 이해해도 된다면, 잘 설명하려면 99%를 이해해야 한다. 그래서 나는 공부하다가 종종 혼자 설명하곤 한다. 말하다보면 내가 말한 걸 내 귀로 듣는다. 그러다 보면 머리속으론 그냥 넘어갔던 부분도 짚는다. "왜 그런가?"를 확실히 생각해보게 된다.

이 설명을 보면서 내가 최소 6개월 정도동안 GAN을 안다고 생각했지만, 사실은 매우 얕게 이해했다는 걸 알게되었다. 충격적.

[출처 : Taeoh Kim's Research Blog](https://taeoh-kim.github.io/blog/image2image/)
```
결국에 CNN은 위 Loss를 기반으로 문제를 풀게 되는데, 문제는 저 합계 또는 평균이다. 각 픽셀별로 가장 완벽한 답을 찾으려고 하기보다는, 전체 픽셀의 관점에서의 Loss를 줄이려고 하기 때문에, 픽셀 값이 정확한 값을 추정하기보다는 안전한 값으로 대충 얼버무리고 넘어간다는 것이다.

이것은 Network의 관점에서는 너무나도 당연한 선택이지만 사람이 봤을때는 Photo-realistic 하지 않다는 문제가 발생한다.

GAN이 유행하기 시작한 이후 GAN이 가지고있는 가장 큰 특징은 VAE와 대비했을 때 극명해지는데, VAE에서는 말 그대로 data distribution을 찾아 내는 확률적 접근성이 짙은 방법이었기 때문에 원론적으로는 더 정확한 접근이라고 볼 수 있으나 마찬가지로 Image에 적용했을 경우 Loss Function이 생겨먹은 것이 그러하듯이 Photo-realistic과는 거리가 멀다.

하지만 GAN은 실제 같은 Data를 만들어 내서 Discriminator를 통해서 학습이 되는 것에 초점을 맞추었고, 그리하여 VAE와는 접근 방법이 다르게 되고 결과가 VAE에 비해 확실한 선택을 하기에 Photo-realistic하게 매우 잘 나온다는 특징이 있다.

결국 이 Idea를 Pix2Pix에 적용하게 되는데, CNN을 통한 Loss Function외에도, GAN Loss를 추가하게 되면 어느 정도 Photo-realistic한 Image를 만들어 내지 않을까 라는 것이다.
```